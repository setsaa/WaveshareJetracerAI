{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importing packages...\")\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import io\n",
    "import gym\n",
    "import gym_donkeycar\n",
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "from jetcam.csi_camera import CSICamera\n",
    "from stable_baselines3 import PPO\n",
    "print(\"Packages imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading model...\")\n",
    "try:\n",
    "    model = PPO.load(\"model_edecay_98305_robert.zip\")\n",
    "except KeyError:\n",
    "    raise Exception(\"ModelError: Model trained in Stable-Baselines2, but trying to load using Stable-Baselines3.\")\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "print(\"Initializing car...\")\n",
    "car = NvidiaRacecar()\n",
    "print(\"Car initialized!\")\n",
    "\n",
    "print(\"Initializing video capture...\")\n",
    "camera = CSICamera(width=224, height=224, capture_fps=65)\n",
    "print(\"Camera ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_orange(image: np.ndarray, lower_bound, upper_bound) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detect orange areas in an image and return a binary mask highlighting those areas.\n",
    "    Args:\n",
    "        image: RGB image array of shape (H, W, 3)\n",
    "    Returns:\n",
    "        Binary mask of shape (H, W) where orange areas are white (255) and others are black (0)\n",
    "    \"\"\"\n",
    "    # Convert image to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Apply the color range mask for orange\n",
    "    orange_mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "            \n",
    "    # Optionally apply some morphological operations to clean up the mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    orange_mask = cv2.morphologyEx(orange_mask, cv2.MORPH_OPEN, kernel)\n",
    "    orange_mask = cv2.morphologyEx(orange_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return orange_mask\n",
    "\n",
    "\n",
    "def preprocess_image(image, lower_bound, upper_bound, crop_height=135):\n",
    "    # Crop top portion\n",
    "    cropped = image[-crop_height:, :, :]\n",
    "\n",
    "    # Detect orange areas in the cropped image\n",
    "    orange_mask = detect_orange(cropped, lower_bound, upper_bound)\n",
    "    \n",
    "    orange_mask = orange_mask.astype(np.float32) / 255.0\n",
    "    \n",
    "    return orange_mask[..., np.newaxis], orange_mask  # Add a channel dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting program...\")\n",
    "ENGAGE_MOTOR = False\n",
    "ENABLE_BACKING_UP = False\n",
    "STEERING_GAIN = 0.5\n",
    "print(f\"ENGAGE_MOTOR: {ENGAGE_MOTOR} | ENABLE_BACKING_UP: {ENABLE_BACKING_UP} | STEERING_GAIN {STEERING_GAIN}\")\n",
    "\n",
    "print(\"Warming up camera...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        image = camera.read()\n",
    "        \n",
    "        orange_lower = (100, 50, 50)  # Lower bound for hue, saturation, value\n",
    "        orange_upper = (125, 255, 255)  # Upper bound for hue, saturation, value\n",
    "        \n",
    "        # Preprocess frame and predict action\n",
    "        input_tensor, orange_mask_raw = preprocess_image(image, lower_bound=orange_lower, upper_bound=orange_upper)\n",
    "        input_tensor = input_tensor.astype(np.float32)\n",
    "        input_tensor = np.expand_dims(input_tensor, axis=0)  # Add batch dimension\n",
    "        \n",
    "        orange_detected = np.count_nonzero(orange_mask_raw) >= 35\n",
    "\n",
    "        if orange_detected or not ENABLE_BACKING_UP:\n",
    "            # Run model inference\n",
    "            with torch.no_grad():\n",
    "                action, _states = model.predict(input_tensor)\n",
    "            print(action)\n",
    "            # Convert action to steering and throttle values\n",
    "            steering = float(action[0][0])\n",
    "            throttle = float(action[0][1])\n",
    "        if not orange_detected and ENABLE_BACKING_UP:\n",
    "            print(\"No orange!\")\n",
    "            steering = 0.0\n",
    "            throttle = -0.3\n",
    "        print(f\"Steering: {steering}, Throttle: {-throttle}\")\n",
    "        \n",
    "        # Apply controls to the car\n",
    "        if ENGAGE_MOTOR:\n",
    "            car.steering = -steering  # Steering controls might be reversed?\n",
    "            if throttle >= 0:\n",
    "                throttle = min(throttle, 0.3)  # Limit speed\n",
    "                throttle += 0.2\n",
    "            car.throttle = -throttle  # Throttle controls are inverted\n",
    "        \n",
    "        # Display the camera feed and preprocessed feed inline in the notebook\n",
    "        rgb_frame = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(rgb_frame).resize((224, 224))\n",
    "        \n",
    "        # Prepare the preprocessed image for display\n",
    "        orange_mask = input_tensor[0, :, :, 0]  # Remove batch and channel dimensions\n",
    "        # Convert mask to a displayable image\n",
    "        mask_img = Image.fromarray((orange_mask * 255).astype(np.uint8)).resize((224, 224))\n",
    "\n",
    "        # Combine the original image and the mask image side by side\n",
    "        combined_width = pil_img.width + mask_img.width\n",
    "        combined_img = Image.new('RGB', (combined_width, pil_img.height))\n",
    "        combined_img.paste(pil_img, (0, 0))\n",
    "        combined_img.paste(mask_img.convert('RGB'), (pil_img.width, 0))\n",
    "\n",
    "        buf_combined = io.BytesIO()\n",
    "        combined_img.save(buf_combined, format='PNG')\n",
    "        buf_combined.seek(0)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(Image.open(buf_combined))\n",
    "                \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting...\")\n",
    "finally:\n",
    "    # Release resources\n",
    "    car.throttle = 0\n",
    "    car.steering = 0\n",
    "    print(\"Resources released and program exited.\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
